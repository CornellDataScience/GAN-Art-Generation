{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T18:54:27.958803Z","iopub.execute_input":"2021-11-20T18:54:27.959088Z","iopub.status.idle":"2021-11-20T18:54:27.962528Z","shell.execute_reply.started":"2021-11-20T18:54:27.959061Z","shell.execute_reply":"2021-11-20T18:54:27.961600Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import (Dense, \n                                     BatchNormalization, \n                                     LeakyReLU, \n                                     Reshape, \n                                     Conv2DTranspose,\n                                     Conv2D,\n                                     Dropout,\n                                     Flatten)\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)\nGCS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:28.374892Z","iopub.execute_input":"2021-11-20T18:54:28.375586Z","iopub.status.idle":"2021-11-20T18:54:35.269991Z","shell.execute_reply.started":"2021-11-20T18:54:28.375539Z","shell.execute_reply":"2021-11-20T18:54:35.269104Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\nPHOTOS = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:35.271724Z","iopub.execute_input":"2021-11-20T18:54:35.272074Z","iopub.status.idle":"2021-11-20T18:54:36.787535Z","shell.execute_reply.started":"2021-11-20T18:54:35.272031Z","shell.execute_reply":"2021-11-20T18:54:36.786599Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\n#scale to [-1,1]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:36.789562Z","iopub.execute_input":"2021-11-20T18:54:36.789987Z","iopub.status.idle":"2021-11-20T18:54:36.798020Z","shell.execute_reply.started":"2021-11-20T18:54:36.789946Z","shell.execute_reply":"2021-11-20T18:54:36.796744Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"monet_ds = load_dataset(MONET_FILENAMES, labeled=True).batch(1)\nphoto_ds = load_dataset(PHOTOS, labeled=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:36.799516Z","iopub.execute_input":"2021-11-20T18:54:36.800171Z","iopub.status.idle":"2021-11-20T18:54:37.008619Z","shell.execute_reply.started":"2021-11-20T18:54:36.800123Z","shell.execute_reply":"2021-11-20T18:54:37.007971Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for element in photo_ds:\n    x=element\n    break","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:37.009637Z","iopub.execute_input":"2021-11-20T18:54:37.010025Z","iopub.status.idle":"2021-11-20T18:54:39.831088Z","shell.execute_reply.started":"2021-11-20T18:54:37.009979Z","shell.execute_reply":"2021-11-20T18:54:39.830442Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y=tf.image.resize(x, [256, 256]) # WAS [28,28]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:54:39.832821Z","iopub.execute_input":"2021-11-20T18:54:39.833441Z","iopub.status.idle":"2021-11-20T18:54:39.847576Z","shell.execute_reply.started":"2021-11-20T18:54:39.833401Z","shell.execute_reply":"2021-11-20T18:54:39.846736Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(Dense(7*7*512, use_bias=False, input_shape=(256,))) #originally 7*7*7, 256*256\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Reshape((7,7,512)))#was 7,7,512\n#     assert model.output_shape == (None, 7, 7, 512) # Note: None is the batch size\n    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)) #originally 128\n#     assert model.output_shape == (None, 7, 7, 128)\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    \n    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)) #originally 64\n#     assert model.output_shape == (None, 14, 14, 64)\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n\n    model.add(Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))#originally 3\n#     print(model.output_shape)\n#     assert model.output_shape == (None, 28, 28, 3)\n    return model\n    #model = tf.keras.Sequential()\n    #model.add(Dense(7*7*512, use_bias=False, input_shape=(256*256,)))\n    #model.add(BatchNormalization())\n    #model.add(LeakyReLU())\n\n    #model.add(Reshape((7,7,512)))\n    #assert model.output_shape == (None, 7, 7, 512) # Note: None is the batch size\n\n    #model.add(Conv2DTranspose(32, kernel_size=(3,3), input_shape=(28,28,3)))\n    #assert model.output_shape == (None, 7, 7, 128)\n    #model.add(Conv2DTranspose(64, (3,3)))\n    #model.add(MaxPooling2D(pool_size=(2,2)))\n    #model.add(Dropout(0.25))\n              \n    #model.add(Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:56:43.835572Z","iopub.execute_input":"2021-11-20T18:56:43.835880Z","iopub.status.idle":"2021-11-20T18:56:43.846661Z","shell.execute_reply.started":"2021-11-20T18:56:43.835851Z","shell.execute_reply":"2021-11-20T18:56:43.845756Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:56:44.437895Z","iopub.execute_input":"2021-11-20T18:56:44.438605Z","iopub.status.idle":"2021-11-20T18:56:44.712472Z","shell.execute_reply.started":"2021-11-20T18:56:44.438558Z","shell.execute_reply":"2021-11-20T18:56:44.711546Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"noise = tf.random.normal([3, 256])*127.5+100\nstarting_image = tf.reshape(x, (3, 256*256))#y[:,:,0:3]\ngenerated_image = generator(noise, training=False)\nplt.imshow(generated_image[0, :, :, 0:3]) #formerly cmap='gray'","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:03:48.571950Z","iopub.execute_input":"2021-11-20T19:03:48.572284Z","iopub.status.idle":"2021-11-20T19:03:48.794499Z","shell.execute_reply.started":"2021-11-20T19:03:48.572221Z","shell.execute_reply":"2021-11-20T19:03:48.793509Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# First descrimnator model\ndef make_discriminator_model():\n    model = tf.keras.Sequential()\n    \n    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 3]))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU())\n    model.add(Dropout(0.3))\n\n    #model.add(Flatten())\n    model.add(Dense(3))\n    print(model.output_shape)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:03:50.634534Z","iopub.execute_input":"2021-11-20T19:03:50.634856Z","iopub.status.idle":"2021-11-20T19:03:50.642108Z","shell.execute_reply.started":"2021-11-20T19:03:50.634824Z","shell.execute_reply":"2021-11-20T19:03:50.641263Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:03:53.205503Z","iopub.execute_input":"2021-11-20T19:03:53.205784Z","iopub.status.idle":"2021-11-20T19:03:53.312167Z","shell.execute_reply.started":"2021-11-20T19:03:53.205757Z","shell.execute_reply":"2021-11-20T19:03:53.311284Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:03:53.892646Z","iopub.execute_input":"2021-11-20T19:03:53.892916Z","iopub.status.idle":"2021-11-20T19:03:53.901495Z","shell.execute_reply.started":"2021-11-20T19:03:53.892889Z","shell.execute_reply":"2021-11-20T19:03:53.900417Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"num_examples_to_generate = 16\nnoise_dim = 256  #WAS 100\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:14:34.166105Z","iopub.execute_input":"2021-11-20T19:14:34.166416Z","iopub.status.idle":"2021-11-20T19:14:34.172619Z","shell.execute_reply.started":"2021-11-20T19:14:34.166385Z","shell.execute_reply":"2021-11-20T19:14:34.171958Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n  \n    # 1 - Create a random noise to feed it into the model\n    # for the image generation\n    #noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    noise = tf.random.normal([3, 256])*127.5+100\n\n    # 2 - Generate images and calculate loss values\n    # GradientTape method records operations for automatic differentiation.\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    # 3 - Calculate gradients using loss values and model variables\n    # \"gradient\" method computes the gradient using \n    # operations recorded in context of this tape (gen_tape and disc_tape).\n    \n    # It accepts a target (e.g., gen_loss) variable and \n    # a source variable (e.g.,generator.trainable_variables)\n    # target --> a list or nested structure of Tensors or Variables to be differentiated.\n    # source --> a list or nested structure of Tensors or Variables.\n    # target will be differentiated against elements in sources.\n\n    # \"gradient\" method returns a list or nested structure of Tensors  \n    # (or IndexedSlices, or None), one for each element in sources. \n    # Returned structure is the same as the structure of sources.\n    gradients_of_generator = gen_tape.gradient(gen_loss, \n                                               generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, \n                                                discriminator.trainable_variables)\n    \n    # 4 - Process  Gradients and Run the Optimizer\n    # \"apply_gradients\" method processes aggregated gradients. \n    # ex: optimizer.apply_gradients(zip(grads, vars))\n    \"\"\"\n    Example use of apply_gradients:\n    grads = tape.gradient(loss, vars)\n    grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n    # Processing aggregated gradients.\n    optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)\n    \"\"\"\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:14:34.685890Z","iopub.execute_input":"2021-11-20T19:14:34.686299Z","iopub.status.idle":"2021-11-20T19:14:34.708555Z","shell.execute_reply.started":"2021-11-20T19:14:34.686268Z","shell.execute_reply":"2021-11-20T19:14:34.707841Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import time\nfrom IPython import display # A command shell for interactive computing in Python.\n\ndef train(dataset, epochs):\n  # A. For each epoch, do the following:\n  for epoch in range(epochs):\n    print(epoch)\n    start = time.time()\n    # 1 - For each batch of the epoch, \n    for image_batch in dataset:\n      # 1.a - run the custom \"train_step\" function\n      # we just declared above\n      train_step(image_batch)\n\n    # 2 - Produce images for the GIF as we go\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    # 3 - Save the model every 5 epochs as \n    # a checkpoint, which we will use later\n    if (epoch + 1) % 5 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    # 4 - Print out the completed epoch no. and the time spent\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # B. Generate a final image after the training is completed\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:14:35.269626Z","iopub.execute_input":"2021-11-20T19:14:35.270053Z","iopub.status.idle":"2021-11-20T19:14:35.276882Z","shell.execute_reply.started":"2021-11-20T19:14:35.270022Z","shell.execute_reply":"2021-11-20T19:14:35.275998Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(4,4))\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i,:,:,0:3]*127.5)\n        plt.axis('off')\n        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n        plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:14:35.850264Z","iopub.execute_input":"2021-11-20T19:14:35.850544Z","iopub.status.idle":"2021-11-20T19:14:35.858379Z","shell.execute_reply.started":"2021-11-20T19:14:35.850515Z","shell.execute_reply":"2021-11-20T19:14:35.857292Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 100\n\ntrain(monet_ds, EPOCHS)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T19:14:36.546713Z","iopub.execute_input":"2021-11-20T19:14:36.546987Z","iopub.status.idle":"2021-11-20T19:17:38.223946Z","shell.execute_reply.started":"2021-11-20T19:14:36.546958Z","shell.execute_reply":"2021-11-20T19:17:38.222717Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}